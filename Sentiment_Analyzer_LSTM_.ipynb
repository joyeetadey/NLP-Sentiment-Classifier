{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0lHhp-FXKKh",
    "outputId": "b6946f02-bb60-4eb3-b628-901cd4c953d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EYwxT_ETX9PS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# preparing input to our model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# keras layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIdECvq2bhnz"
   },
   "source": [
    "## labels: joy, anger, fear, sadness, neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4dwdhVZXY9tr"
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "embed_num_dims = 300\n",
    "\n",
    "max_seq_len = 500\n",
    "\n",
    "class_names = ['joy', 'fear', 'anger', 'sadness', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1c6x_kvbWhS"
   },
   "source": [
    "## Testing and Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "Qxq-VX45ZwPY",
    "outputId": "d0e477ef-1032-40c5-9494-5b9783aad2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When my family heard that my Mother's cousin w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so...\n",
       "5  sadness  When my family heard that my Mother's cousin w..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('/content/drive/MyDrive/nlp-text-emotion-master/data/data_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('/content/drive/MyDrive/nlp-text-emotion-master/data/data_test.csv', encoding='utf-8')\n",
    "\n",
    "X_train = data_train.Text\n",
    "X_test = data_test.Text\n",
    "\n",
    "y_train = data_train.Emotion\n",
    "y_test = data_test.Emotion\n",
    "\n",
    "data = data_train.append(data_test, ignore_index=True)\n",
    "print(data.Emotion.value_counts())\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tScFDmqebtAm"
   },
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "### **Tokenize:** our texts and count unique tokens\n",
    "### **Padding:** each input (sentence or text) has to be of the same lenght\n",
    "### **Encoding:** Labels have to be converted to integeres and categorized\n",
    "### **Pre trained Word-to-Vec model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "La4rr-5KbUNr"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(data):\n",
    "    \n",
    "    # remove hashtags and @usernames\n",
    "    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "    \n",
    "    # tekenization using nltk\n",
    "    data = word_tokenize(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1RInBBIcWJ1",
    "outputId": "1e412ec2-0e14-4ae6-b975-cde08d475a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Yet the dog had grown old and less capable , and one day the gillie had come and explained with great sorrow that the dog had suffered a stroke , and must be put down .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "texts = [' '.join(clean_text(text)) for text in data.Text]\n",
    "\n",
    "texts_train = [' '.join(clean_text(text)) for text in X_train]\n",
    "texts_test = [' '.join(clean_text(text)) for text in X_test]\n",
    "print(texts_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofLOMy6lc3d6"
   },
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfgBxWbcctU6",
    "outputId": "4223d5be-65da-4d7b-96c1-cf89c101c347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 12088\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "# vacab size is number of unique words + reserved 0 index for padding\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6fxVK7Fc8Ia"
   },
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GpDtnf_c5Vd",
    "outputId": "dc8a1114-527f-4951-d2c2-ba9f8d13c3d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   119,    51,   345],\n",
       "       [    0,     0,     0, ...,    37,   277,   154],\n",
       "       [    0,     0,     0, ...,    16,     2,  1210],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   876,     4,   909],\n",
       "       [    0,     0,     0, ...,     1,     6,   117],\n",
       "       [    0,     0,     0, ..., 10259,   173,    13]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len )\n",
    "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len )\n",
    "\n",
    "X_train_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMRcHR1hdBck"
   },
   "source": [
    "Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6L8EM9Hoc9XA",
    "outputId": "6dacb52a-6ed1-4e83-9cb7-b289bff7a3f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'fear': 1,\n",
    "    'anger': 2,\n",
    "    'sadness': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer labels\n",
    "y_train = [encoding[x] for x in data_train.Emotion]\n",
    "y_test = [encoding[x] for x in data_test.Emotion]\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsFPS6NUdKMh"
   },
   "source": [
    "Import pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A4FrSVzTdEWV"
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlFUetRbdOcv",
    "outputId": "f5f15bdc-da86-4f7e-f915-4a6e31e8347e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "fname = 'embeddings/wiki-news-300d-1M.vec'\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    # print('Downloading word vectors...')\n",
    "    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip','wiki-news-300d-1M.vec.zip')\n",
    "    # print('Unzipping...')\n",
    "    with zipfile.ZipFile('wiki-news-300d-1M.vec.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('embeddings')\n",
    "    print('done.')\n",
    "    \n",
    "    os.remove('wiki-news-300d-1M.vec.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toAevv5BdVMT",
    "outputId": "fa0be391-ed22-4218-fec0-144c8b3ba8af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12089, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd_matrix = create_embedding_matrix(fname, index_of_words, embed_num_dims)\n",
    "embedd_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYhSdCMPehHI"
   },
   "source": [
    "## Create LSTM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eko_O7eelOl"
   },
   "source": [
    "Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TFw9J4ItdZdp"
   },
   "outputs": [],
   "source": [
    "# Embedding layer before the actaul LSTM \n",
    "embedd_layer = Embedding(vocab_size,\n",
    "                         embed_num_dims,\n",
    "                         input_length = max_seq_len,\n",
    "                         weights = [embedd_matrix],\n",
    "                         trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY8mMoqPerqV"
   },
   "source": [
    "### Model Pipeline\n",
    "*   the input is the first N words of each text\n",
    "*   the first level creates embedding of words, using vocabulary with a certain dimension, and a given size of embeddings\n",
    "*   the output level has a number of neurons equal to the classes of the problem and a “softmax” activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5kznwBLgZ_h"
   },
   "source": [
    "#### Embedding Layer, LSTM, Dense, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdfEttSweIxU",
    "outputId": "c9713d5f-3647-468b-91e2-05c8d999606f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 300)          3626700   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               165120    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,792,465\n",
      "Trainable params: 165,765\n",
      "Non-trainable params: 3,626,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "gru_output_size = 128\n",
    "bidirectional = True\n",
    "\n",
    "# Embedding Layer, LSTM or biLSTM, Dense, softmax\n",
    "model = Sequential()\n",
    "model.add(embedd_layer)\n",
    "model.add(GRU(units=gru_output_size,\n",
    "              dropout=0.2, \n",
    "              recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjAW1_BjfYdN"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "hist = model.fit(X_train_pad, y_train, \n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZwzcvYePPTX"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/sentiment-analyzer/models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgKNNvHtPLWF"
   },
   "source": [
    "## Prediction and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27QJtW5VfulT"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_pad)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions = [class_names[pred] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdPiYvsPvuw9",
    "outputId": "fe75f6dc-6b9f-49bf-e792-472f8cf236a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.24%\n",
      "\n",
      "F1 Score: 73.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(data_test.Emotion, predictions) * 100))\n",
    "print(\"\\nF1 Score: {:.2f}\".format(f1_score(data_test.Emotion, predictions, average='micro') * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dppiCPvPyLwt",
    "outputId": "f9432da4-a90d-4615-ad52-c2b6d75b92cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: However , does the right hon. Gentleman recognise that profound disquiet has been expressed about some of the proposals in the Bill , particularly the fast-track ones ? \n",
      "Predicted: fear\n"
     ]
    }
   ],
   "source": [
    "print('Message: {}\\nPredicted: {}'.format(X_test[3], predictions[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oyLOLI_9ENy",
    "outputId": "9a9046ab-9cd2-4520-f602-149075b1ef89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 300)          3626400   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               329472    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,957,157\n",
      "Trainable params: 330,757\n",
      "Non-trainable params: 3,626,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/content/drive/MyDrive/nlp-text-emotion-master/models/biLSTM_w2v.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjFvIsUsOk4b"
   },
   "source": [
    "### Testing with random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGe97GQ_864Q",
    "outputId": "072cc28e-2f61-49e6-a698-92cce2badc8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: ['this is a very delicious recipe']\n",
      "predicted: joy\n"
     ]
    }
   ],
   "source": [
    "message = [\"this is a very delicious recipe\"]\n",
    "\n",
    "seq = tokenizer.texts_to_sequences(message)\n",
    "padded = pad_sequences(seq, maxlen=max_seq_len)\n",
    "\n",
    "pred = model.predict(padded)\n",
    "\n",
    "print('Message: ' + str(message))\n",
    "print('predicted: {}'.format(class_names[np.argmax(pred)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdResiMJwVpp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment Analyzer LSTM .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
